{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HpQzdbft7n-y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset class for preprocessing\n",
        "class LossTriangleDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        x = np.expand_dims(x, axis=0)  # Add channel dimension\n",
        "        y = self.labels[index]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_data(dataframe):\n",
        "        # Drop ay column\n",
        "        dataframe = dataframe.drop('ay', axis=1)\n",
        "\n",
        "        # Replace infinity values with NaN\n",
        "        dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "        # Remove nan values and normalize data\n",
        "        scaler = StandardScaler()\n",
        "        for triangle_id in dataframe['triangle_id'].unique():\n",
        "            df_triangle = dataframe[dataframe['triangle_id'] == triangle_id].iloc[:, 2:]\n",
        "            df_triangle = df_triangle.dropna(axis=1, how='all')\n",
        "            dataframe.loc[dataframe['triangle_id'] == triangle_id, df_triangle.columns] = scaler.fit_transform(df_triangle)\n",
        "\n",
        "        # Find the maximum number of rows\n",
        "        max_rows = max([len(dataframe[dataframe['triangle_id'] == triangle_id]) for triangle_id in dataframe['triangle_id'].unique()])\n",
        "\n",
        "        # Replace \"nan\" values with 0\n",
        "        dataframe.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "        # Create data and labels\n",
        "        data = []\n",
        "        labels = []\n",
        "        for triangle_id in dataframe['triangle_id'].unique():\n",
        "            df_triangle = dataframe[dataframe['triangle_id'] == triangle_id].iloc[:, 1:]\n",
        "            label = df_triangle.iloc[-1, 0]\n",
        "            triangle_data = df_triangle.iloc[:, 1:].values\n",
        "\n",
        "            # Zero-padding\n",
        "            nrows = triangle_data.shape[0]\n",
        "            padded_triangle_data = np.zeros((max_rows, max_rows))\n",
        "            for row_idx, row_data in enumerate(triangle_data):\n",
        "                padded_triangle_data[row_idx, :max_rows-row_idx] = row_data[:max_rows-row_idx]\n",
        "\n",
        "            data.append(padded_triangle_data)\n",
        "            labels.append(label)\n",
        "\n",
        "        # Convert data and labels to numpy arrays\n",
        "        data = np.stack(data, axis=0)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Check if there are any \"nan\" or infinite values in the data and labels\n",
        "        assert not np.isnan(data).any(), \"Data contains 'nan' values\"\n",
        "        assert not np.isinf(data).any(), \"Data contains infinite values\"\n",
        "        assert not np.isnan(labels).any(), \"Labels contain 'nan' values\"\n",
        "        assert not np.isinf(labels).any(), \"Labels contain infinite values\"\n",
        "\n",
        "        return data, labels\n",
        "\n",
        "    @staticmethod\n",
        "    def create_datasets(dataframe, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
        "        data, labels = LossTriangleDataset.preprocess_data(dataframe)\n",
        "        train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=test_ratio, random_state=42)\n",
        "        train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=val_ratio / (train_ratio + val_ratio), random_state=42)\n",
        "\n",
        "        train_dataset = LossTriangleDataset(train_data, train_labels)\n",
        "        val_dataset = LossTriangleDataset(val_data, val_labels)\n",
        "        test_dataset = LossTriangleDataset(test_data, test_labels)\n",
        "\n",
        "        return train_dataset, val_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "oUIWKy1s8eXB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "OnaSgvHXqVZp",
        "outputId": "3363f4c6-3cb6-46ec-e1b6-07f88aa7f9e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-178f4a3245cd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn model class\n",
        "class LossTriangleClassifier(nn.Module):\n",
        "    def __init__(self, input_shape, num_classes=2, dropout_rate=0.5):\n",
        "        super(LossTriangleClassifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(2, 2), padding=(1, 1))\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 2), padding=(1, 1))\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(2, 2), padding=(1, 1))\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._get_flattened_size(input_shape), 512)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.leaky_relu(self.conv1(x), 0.1))\n",
        "        x = self.pool2(F.leaky_relu(self.conv2(x), 0.1))\n",
        "        x = self.pool3(F.leaky_relu(self.conv3(x), 0.1))\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "    def _get_flattened_size(self, input_shape):\n",
        "        dummy_input = torch.zeros(1, *input_shape)\n",
        "        # dummy_output = self.pool3(F.leaky_relu(self.conv3(self.pool2(F.leaky_relu(self.conv2(self.pool1(F.leaky_relu(self.conv1(dummy_input)))))))))\n",
        "        dummy_output = self.pool3(F.leaky_relu(self.bn3(self.conv3(self.pool2(F.leaky_relu(self.bn2(self.conv2(self.pool1(F.leaky_relu(self.bn1(self.conv1(dummy_input))))))))))))\n",
        "        return dummy_output.numel()\n"
      ],
      "metadata": {
        "id": "K0sn99x68f_s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # cnn model class\n",
        "# class LossTriangleClassifier2(nn.Module):\n",
        "#     def __init__(self, input_shape, num_classes=2, dropout_rate=0.5):\n",
        "#         super(LossTriangleClassifier2, self).__init__()\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=(2, 2), padding=(1, 1), bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(16)\n",
        "#         # self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 2), padding=(1, 1), bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(32)\n",
        "#         # self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=(2, 2), padding=(1, 1), bias=False)\n",
        "#         self.bn3 = nn.BatchNorm2d(64)\n",
        "#         # self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "#         self.conv4 = nn.Conv2d(64, 32, kernel_size=(2, 2), padding=(1, 1), bias=False)\n",
        "#         self.bn4 = nn.BatchNorm2d(32)\n",
        "\n",
        "#         self.conv5 = nn.Conv2d(32, 16, kernel_size=(2, 2), padding=(1, 1), bias=False)\n",
        "#         self.bn5 = nn.BatchNorm2d(16)\n",
        "\n",
        "#         self.flatten = nn.Flatten()\n",
        "\n",
        "#         self.fc1 = nn.Linear(self._get_flattened_size(input_shape), 512)\n",
        "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
        "#         self.fc2 = nn.Linear(512, num_classes)\n",
        "#         self.dropout2 = nn.Dropout(dropout_rate)\n",
        "#         self.fc3 = nn.Linear(512, num_classes)\n",
        "#         self.dropout3 = nn.Dropout(dropout_rate)\n",
        "#         self.fc4 = nn.Linear(512, num_classes)\n",
        "#         self.dropout4 = nn.Dropout(dropout_rate)\n",
        "#         self.fc5 = nn.Linear(512, num_classes)\n",
        "#         # self.dropout5 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)\n",
        "#         x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n",
        "#         x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n",
        "#         x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)\n",
        "#         x = F.leaky_relu(self.bn5(self.conv5(x)), 0.2)\n",
        "\n",
        "#         x = self.flatten(x)\n",
        "#         x = F.leaky_relu(self.fc1(x))\n",
        "#         x = self.dropout1(x)\n",
        "#         x = self.dropout2(F.leaky_relu(self.fc2(x)))\n",
        "#         x = self.dropout3(F.leaky_relu(self.fc3(x)))\n",
        "#         x = self.dropout4(F.leaky_relu(self.fc4(x)))\n",
        "#         x = self.fc5(x)\n",
        "\n",
        "#         return torch.sigmoid(x)\n",
        "\n",
        "#     def _get_flattened_size(self, input_shape):\n",
        "#         dummy_input = torch.zeros(1, *input_shape)\n",
        "#         dummy_output = self.conv5(\n",
        "#             self.bn5(\n",
        "#                 F.leaky_relu(\n",
        "#                     self.conv4(\n",
        "#                         self.bn4(\n",
        "#                             F.leaky_relu(\n",
        "#                                 self.conv3(\n",
        "#                                     self.bn3(\n",
        "#                                         F.leaky_relu\n",
        "#                 self.bn4(\n",
        "#             F.leaky_relu(\n",
        "#                 self.conv3(\n",
        "#                     F.leaky_relu(\n",
        "#                         self.conv2(\n",
        "#                             F.leaky_relu(\n",
        "#                                 self.conv1(\n",
        "#                                     dummy_input\n",
        "#                                             ))))))\n",
        "#         # dummy_output = self.pool3(F.leaky_relu(self.bn3(self.conv3(self.pool2(F.leaky_relu(self.bn2(self.conv2(self.pool1(F.leaky_relu(self.bn1(self.conv1(dummy_input))))))))))))\n",
        "#         return dummy_output.numel()\n"
      ],
      "metadata": {
        "id": "RcnXaee0hmGL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model function\n",
        "def train_model(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    return running_loss / len(dataloader.dataset), correct / total\n",
        "\n"
      ],
      "metadata": {
        "id": "K4R9ExWD8iG4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate model function\n",
        "def validate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = correct / total\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "PfSpbULk8j_2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model:\n",
        "def main(datafile='naic.feather', num_epochs = 200):\n",
        "    # Load data\n",
        "    dataframe = pd.read_feather(datafile)\n",
        "    print(f'data head: \\n{dataframe.head()}')\n",
        "    train_dataset, val_dataset, test_dataset = LossTriangleDataset.create_datasets(dataframe)\n",
        "\n",
        "    # print(f\"train set: {train_dataset}\")\n",
        "    # print(f\"validation set: {val_dataset}\")\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # print(f\"train loader: {train_loader}\")\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"device: {device}\")\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    input_shape = train_dataset[0][0].shape\n",
        "    model = LossTriangleClassifier(input_shape).to(device)\n",
        "    # criterion = nn.BCELoss()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "    # print(f\"input_shape: {input_shape}\")\n",
        "  \n",
        "\n",
        "    # Train and validate model\n",
        "    \n",
        "    train_list, val_list = [], []\n",
        "    t_acc_list, v_acc_list = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, t_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, v_acc = validate_model(model, val_loader, criterion, device)\n",
        "        train_list.append(train_loss)\n",
        "        val_list.append(val_loss)\n",
        "        t_acc_list.append(t_acc)\n",
        "        v_acc_list.append(v_acc)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Training Loss: {train_loss:.4f} / Validation Loss: {val_loss:.4f}')\n",
        "        print(f'Training Accuracy: {t_acc:.1%}  / Validation Accuracy: {v_acc:.1%}')\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            test_predictions.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    # Print the predictions\n",
        "    print(\"Predictions on the test set:\", test_predictions)\n",
        "\n",
        "    return train_list, val_list, t_acc_list, v_acc_list, test_predictions, test_dataset"
      ],
      "metadata": {
        "id": "JlObznrJ8l3E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss, train_acc, val_acc, test_pred, test_dataset = main('/content/drive/MyDrive/naic.feather', 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQsM4SUK8npq",
        "outputId": "1956cad4-b161-4a42-f26d-5c00dc73bcf4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data head: \n",
            "   triangle_id  is_cum    ay       1        2        3        4        5  \\\n",
            "0            0       1  1988   133.0    333.0    431.0    570.0    615.0   \n",
            "1            0       1  1989   934.0   1746.0   2365.0   2579.0   2763.0   \n",
            "2            0       1  1990  2030.0   4864.0   6880.0   8087.0   8595.0   \n",
            "3            0       1  1991  4537.0  11527.0  15123.0  16656.0  17321.0   \n",
            "4            0       1  1992  7564.0  16061.0  22465.0  25204.0  26517.0   \n",
            "\n",
            "         6        7       8       9     10  \n",
            "0    615.0    615.0   614.0   614.0  614.0  \n",
            "1   2966.0   2940.0  2978.0  2978.0    NaN  \n",
            "2   8743.0   8763.0  8762.0     NaN    NaN  \n",
            "3  18076.0  18308.0     NaN     NaN    NaN  \n",
            "4  27124.0      NaN     NaN     NaN    NaN  \n",
            "device: cuda\n",
            "Epoch 1/1000\n",
            "Training Loss: 0.6932 / Validation Loss: 0.6929\n",
            "Training Accuracy: 50.4%  / Validation Accuracy: 59.8%\n",
            "Epoch 2/1000\n",
            "Training Loss: 0.6924 / Validation Loss: 0.6924\n",
            "Training Accuracy: 52.6%  / Validation Accuracy: 65.6%\n",
            "Epoch 3/1000\n",
            "Training Loss: 0.6919 / Validation Loss: 0.6919\n",
            "Training Accuracy: 53.5%  / Validation Accuracy: 48.8%\n",
            "Epoch 4/1000\n",
            "Training Loss: 0.6911 / Validation Loss: 0.6911\n",
            "Training Accuracy: 55.1%  / Validation Accuracy: 49.6%\n",
            "Epoch 5/1000\n",
            "Training Loss: 0.6903 / Validation Loss: 0.6902\n",
            "Training Accuracy: 55.4%  / Validation Accuracy: 48.9%\n",
            "Epoch 6/1000\n",
            "Training Loss: 0.6893 / Validation Loss: 0.6891\n",
            "Training Accuracy: 56.2%  / Validation Accuracy: 48.9%\n",
            "Epoch 7/1000\n",
            "Training Loss: 0.6876 / Validation Loss: 0.6874\n",
            "Training Accuracy: 59.6%  / Validation Accuracy: 55.3%\n",
            "Epoch 8/1000\n",
            "Training Loss: 0.6856 / Validation Loss: 0.6852\n",
            "Training Accuracy: 60.5%  / Validation Accuracy: 55.6%\n",
            "Epoch 9/1000\n",
            "Training Loss: 0.6828 / Validation Loss: 0.6822\n",
            "Training Accuracy: 62.2%  / Validation Accuracy: 65.1%\n",
            "Epoch 10/1000\n",
            "Training Loss: 0.6799 / Validation Loss: 0.6782\n",
            "Training Accuracy: 64.0%  / Validation Accuracy: 76.7%\n",
            "Epoch 11/1000\n",
            "Training Loss: 0.6754 / Validation Loss: 0.6733\n",
            "Training Accuracy: 70.1%  / Validation Accuracy: 79.8%\n",
            "Epoch 12/1000\n",
            "Training Loss: 0.6701 / Validation Loss: 0.6672\n",
            "Training Accuracy: 71.5%  / Validation Accuracy: 82.9%\n",
            "Epoch 13/1000\n",
            "Training Loss: 0.6636 / Validation Loss: 0.6594\n",
            "Training Accuracy: 73.1%  / Validation Accuracy: 83.2%\n",
            "Epoch 14/1000\n",
            "Training Loss: 0.6544 / Validation Loss: 0.6492\n",
            "Training Accuracy: 75.5%  / Validation Accuracy: 83.8%\n",
            "Epoch 15/1000\n",
            "Training Loss: 0.6447 / Validation Loss: 0.6368\n",
            "Training Accuracy: 76.2%  / Validation Accuracy: 84.1%\n",
            "Epoch 16/1000\n",
            "Training Loss: 0.6328 / Validation Loss: 0.6225\n",
            "Training Accuracy: 76.9%  / Validation Accuracy: 84.5%\n",
            "Epoch 17/1000\n",
            "Training Loss: 0.6218 / Validation Loss: 0.6077\n",
            "Training Accuracy: 76.2%  / Validation Accuracy: 84.5%\n",
            "Epoch 18/1000\n",
            "Training Loss: 0.6111 / Validation Loss: 0.5927\n",
            "Training Accuracy: 76.3%  / Validation Accuracy: 84.8%\n",
            "Epoch 19/1000\n",
            "Training Loss: 0.6002 / Validation Loss: 0.5779\n",
            "Training Accuracy: 76.4%  / Validation Accuracy: 84.6%\n",
            "Epoch 20/1000\n",
            "Training Loss: 0.5931 / Validation Loss: 0.5654\n",
            "Training Accuracy: 76.8%  / Validation Accuracy: 84.6%\n",
            "Epoch 21/1000\n",
            "Training Loss: 0.5871 / Validation Loss: 0.5543\n",
            "Training Accuracy: 77.0%  / Validation Accuracy: 84.7%\n",
            "Epoch 22/1000\n",
            "Training Loss: 0.5822 / Validation Loss: 0.5448\n",
            "Training Accuracy: 75.7%  / Validation Accuracy: 84.8%\n",
            "Epoch 23/1000\n",
            "Training Loss: 0.5754 / Validation Loss: 0.5367\n",
            "Training Accuracy: 77.0%  / Validation Accuracy: 84.8%\n",
            "Epoch 24/1000\n",
            "Training Loss: 0.5755 / Validation Loss: 0.5286\n",
            "Training Accuracy: 77.1%  / Validation Accuracy: 84.8%\n",
            "Epoch 25/1000\n",
            "Training Loss: 0.5749 / Validation Loss: 0.5233\n",
            "Training Accuracy: 75.3%  / Validation Accuracy: 84.8%\n",
            "Epoch 26/1000\n",
            "Training Loss: 0.5727 / Validation Loss: 0.5185\n",
            "Training Accuracy: 76.8%  / Validation Accuracy: 84.8%\n",
            "Epoch 27/1000\n",
            "Training Loss: 0.5705 / Validation Loss: 0.5120\n",
            "Training Accuracy: 76.7%  / Validation Accuracy: 85.2%\n",
            "Epoch 28/1000\n",
            "Training Loss: 0.5631 / Validation Loss: 0.5074\n",
            "Training Accuracy: 76.9%  / Validation Accuracy: 84.7%\n",
            "Epoch 29/1000\n",
            "Training Loss: 0.5662 / Validation Loss: 0.5036\n",
            "Training Accuracy: 76.6%  / Validation Accuracy: 84.6%\n",
            "Epoch 30/1000\n",
            "Training Loss: 0.5638 / Validation Loss: 0.5000\n",
            "Training Accuracy: 75.9%  / Validation Accuracy: 84.7%\n",
            "Epoch 31/1000\n",
            "Training Loss: 0.5620 / Validation Loss: 0.4970\n",
            "Training Accuracy: 77.4%  / Validation Accuracy: 84.5%\n",
            "Epoch 32/1000\n",
            "Training Loss: 0.5612 / Validation Loss: 0.4936\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 84.7%\n",
            "Epoch 33/1000\n",
            "Training Loss: 0.5600 / Validation Loss: 0.4925\n",
            "Training Accuracy: 77.2%  / Validation Accuracy: 84.9%\n",
            "Epoch 34/1000\n",
            "Training Loss: 0.5533 / Validation Loss: 0.4885\n",
            "Training Accuracy: 77.4%  / Validation Accuracy: 84.5%\n",
            "Epoch 35/1000\n",
            "Training Loss: 0.5593 / Validation Loss: 0.4871\n",
            "Training Accuracy: 76.5%  / Validation Accuracy: 84.8%\n",
            "Epoch 36/1000\n",
            "Training Loss: 0.5579 / Validation Loss: 0.4848\n",
            "Training Accuracy: 77.4%  / Validation Accuracy: 84.9%\n",
            "Epoch 37/1000\n",
            "Training Loss: 0.5578 / Validation Loss: 0.4841\n",
            "Training Accuracy: 77.6%  / Validation Accuracy: 85.2%\n",
            "Epoch 38/1000\n",
            "Training Loss: 0.5586 / Validation Loss: 0.4814\n",
            "Training Accuracy: 77.1%  / Validation Accuracy: 85.1%\n",
            "Epoch 39/1000\n",
            "Training Loss: 0.5591 / Validation Loss: 0.4798\n",
            "Training Accuracy: 76.5%  / Validation Accuracy: 85.1%\n",
            "Epoch 40/1000\n",
            "Training Loss: 0.5586 / Validation Loss: 0.4793\n",
            "Training Accuracy: 77.0%  / Validation Accuracy: 85.2%\n",
            "Epoch 41/1000\n",
            "Training Loss: 0.5572 / Validation Loss: 0.4784\n",
            "Training Accuracy: 77.1%  / Validation Accuracy: 85.6%\n",
            "Epoch 42/1000\n",
            "Training Loss: 0.5569 / Validation Loss: 0.4766\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 85.6%\n",
            "Epoch 43/1000\n",
            "Training Loss: 0.5547 / Validation Loss: 0.4751\n",
            "Training Accuracy: 77.0%  / Validation Accuracy: 85.6%\n",
            "Epoch 44/1000\n",
            "Training Loss: 0.5534 / Validation Loss: 0.4743\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 85.4%\n",
            "Epoch 45/1000\n",
            "Training Loss: 0.5552 / Validation Loss: 0.4731\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.4%\n",
            "Epoch 46/1000\n",
            "Training Loss: 0.5526 / Validation Loss: 0.4716\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.5%\n",
            "Epoch 47/1000\n",
            "Training Loss: 0.5516 / Validation Loss: 0.4707\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 85.4%\n",
            "Epoch 48/1000\n",
            "Training Loss: 0.5568 / Validation Loss: 0.4692\n",
            "Training Accuracy: 77.3%  / Validation Accuracy: 85.3%\n",
            "Epoch 49/1000\n",
            "Training Loss: 0.5515 / Validation Loss: 0.4684\n",
            "Training Accuracy: 77.9%  / Validation Accuracy: 85.2%\n",
            "Epoch 50/1000\n",
            "Training Loss: 0.5525 / Validation Loss: 0.4676\n",
            "Training Accuracy: 77.6%  / Validation Accuracy: 85.4%\n",
            "Epoch 51/1000\n",
            "Training Loss: 0.5497 / Validation Loss: 0.4670\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 85.6%\n",
            "Epoch 52/1000\n",
            "Training Loss: 0.5531 / Validation Loss: 0.4671\n",
            "Training Accuracy: 77.5%  / Validation Accuracy: 85.5%\n",
            "Epoch 53/1000\n",
            "Training Loss: 0.5516 / Validation Loss: 0.4657\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.6%\n",
            "Epoch 54/1000\n",
            "Training Loss: 0.5489 / Validation Loss: 0.4649\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.6%\n",
            "Epoch 55/1000\n",
            "Training Loss: 0.5513 / Validation Loss: 0.4645\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.4%\n",
            "Epoch 56/1000\n",
            "Training Loss: 0.5530 / Validation Loss: 0.4638\n",
            "Training Accuracy: 77.6%  / Validation Accuracy: 85.4%\n",
            "Epoch 57/1000\n",
            "Training Loss: 0.5506 / Validation Loss: 0.4633\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 85.3%\n",
            "Epoch 58/1000\n",
            "Training Loss: 0.5521 / Validation Loss: 0.4609\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 85.5%\n",
            "Epoch 59/1000\n",
            "Training Loss: 0.5508 / Validation Loss: 0.4601\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.6%\n",
            "Epoch 60/1000\n",
            "Training Loss: 0.5516 / Validation Loss: 0.4616\n",
            "Training Accuracy: 76.8%  / Validation Accuracy: 85.4%\n",
            "Epoch 61/1000\n",
            "Training Loss: 0.5490 / Validation Loss: 0.4602\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.5%\n",
            "Epoch 62/1000\n",
            "Training Loss: 0.5513 / Validation Loss: 0.4585\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.6%\n",
            "Epoch 63/1000\n",
            "Training Loss: 0.5494 / Validation Loss: 0.4583\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 85.6%\n",
            "Epoch 64/1000\n",
            "Training Loss: 0.5494 / Validation Loss: 0.4583\n",
            "Training Accuracy: 77.9%  / Validation Accuracy: 85.6%\n",
            "Epoch 65/1000\n",
            "Training Loss: 0.5469 / Validation Loss: 0.4568\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 85.7%\n",
            "Epoch 66/1000\n",
            "Training Loss: 0.5512 / Validation Loss: 0.4582\n",
            "Training Accuracy: 77.5%  / Validation Accuracy: 85.2%\n",
            "Epoch 67/1000\n",
            "Training Loss: 0.5539 / Validation Loss: 0.4563\n",
            "Training Accuracy: 78.3%  / Validation Accuracy: 85.6%\n",
            "Epoch 68/1000\n",
            "Training Loss: 0.5502 / Validation Loss: 0.4574\n",
            "Training Accuracy: 77.6%  / Validation Accuracy: 85.4%\n",
            "Epoch 69/1000\n",
            "Training Loss: 0.5487 / Validation Loss: 0.4557\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.6%\n",
            "Epoch 70/1000\n",
            "Training Loss: 0.5472 / Validation Loss: 0.4561\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.4%\n",
            "Epoch 71/1000\n",
            "Training Loss: 0.5449 / Validation Loss: 0.4544\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 85.9%\n",
            "Epoch 72/1000\n",
            "Training Loss: 0.5491 / Validation Loss: 0.4544\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.6%\n",
            "Epoch 73/1000\n",
            "Training Loss: 0.5487 / Validation Loss: 0.4547\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.0%\n",
            "Epoch 74/1000\n",
            "Training Loss: 0.5478 / Validation Loss: 0.4541\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 85.1%\n",
            "Epoch 75/1000\n",
            "Training Loss: 0.5492 / Validation Loss: 0.4541\n",
            "Training Accuracy: 78.3%  / Validation Accuracy: 85.1%\n",
            "Epoch 76/1000\n",
            "Training Loss: 0.5466 / Validation Loss: 0.4528\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.0%\n",
            "Epoch 77/1000\n",
            "Training Loss: 0.5488 / Validation Loss: 0.4527\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.5%\n",
            "Epoch 78/1000\n",
            "Training Loss: 0.5480 / Validation Loss: 0.4523\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 86.2%\n",
            "Epoch 79/1000\n",
            "Training Loss: 0.5489 / Validation Loss: 0.4533\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.3%\n",
            "Epoch 80/1000\n",
            "Training Loss: 0.5446 / Validation Loss: 0.4514\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.6%\n",
            "Epoch 81/1000\n",
            "Training Loss: 0.5473 / Validation Loss: 0.4521\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.6%\n",
            "Epoch 82/1000\n",
            "Training Loss: 0.5463 / Validation Loss: 0.4519\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 85.6%\n",
            "Epoch 83/1000\n",
            "Training Loss: 0.5488 / Validation Loss: 0.4503\n",
            "Training Accuracy: 77.2%  / Validation Accuracy: 86.0%\n",
            "Epoch 84/1000\n",
            "Training Loss: 0.5471 / Validation Loss: 0.4502\n",
            "Training Accuracy: 78.2%  / Validation Accuracy: 85.6%\n",
            "Epoch 85/1000\n",
            "Training Loss: 0.5501 / Validation Loss: 0.4513\n",
            "Training Accuracy: 77.7%  / Validation Accuracy: 85.6%\n",
            "Epoch 86/1000\n",
            "Training Loss: 0.5481 / Validation Loss: 0.4507\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 85.7%\n",
            "Epoch 87/1000\n",
            "Training Loss: 0.5441 / Validation Loss: 0.4500\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.0%\n",
            "Epoch 88/1000\n",
            "Training Loss: 0.5464 / Validation Loss: 0.4491\n",
            "Training Accuracy: 78.2%  / Validation Accuracy: 85.9%\n",
            "Epoch 89/1000\n",
            "Training Loss: 0.5465 / Validation Loss: 0.4496\n",
            "Training Accuracy: 77.9%  / Validation Accuracy: 86.0%\n",
            "Epoch 90/1000\n",
            "Training Loss: 0.5472 / Validation Loss: 0.4505\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 85.2%\n",
            "Epoch 91/1000\n",
            "Training Loss: 0.5509 / Validation Loss: 0.4491\n",
            "Training Accuracy: 77.7%  / Validation Accuracy: 85.9%\n",
            "Epoch 92/1000\n",
            "Training Loss: 0.5464 / Validation Loss: 0.4487\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 85.8%\n",
            "Epoch 93/1000\n",
            "Training Loss: 0.5477 / Validation Loss: 0.4483\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 86.0%\n",
            "Epoch 94/1000\n",
            "Training Loss: 0.5481 / Validation Loss: 0.4475\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 86.1%\n",
            "Epoch 95/1000\n",
            "Training Loss: 0.5470 / Validation Loss: 0.4480\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 86.0%\n",
            "Epoch 96/1000\n",
            "Training Loss: 0.5485 / Validation Loss: 0.4470\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.1%\n",
            "Epoch 97/1000\n",
            "Training Loss: 0.5468 / Validation Loss: 0.4469\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 86.1%\n",
            "Epoch 98/1000\n",
            "Training Loss: 0.5444 / Validation Loss: 0.4470\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 86.2%\n",
            "Epoch 99/1000\n",
            "Training Loss: 0.5486 / Validation Loss: 0.4474\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 85.6%\n",
            "Epoch 100/1000\n",
            "Training Loss: 0.5458 / Validation Loss: 0.4472\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 85.6%\n",
            "Epoch 101/1000\n",
            "Training Loss: 0.5453 / Validation Loss: 0.4464\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 85.9%\n",
            "Epoch 102/1000\n",
            "Training Loss: 0.5462 / Validation Loss: 0.4464\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 85.8%\n",
            "Epoch 103/1000\n",
            "Training Loss: 0.5457 / Validation Loss: 0.4463\n",
            "Training Accuracy: 78.2%  / Validation Accuracy: 85.7%\n",
            "Epoch 104/1000\n",
            "Training Loss: 0.5459 / Validation Loss: 0.4459\n",
            "Training Accuracy: 77.8%  / Validation Accuracy: 86.2%\n",
            "Epoch 105/1000\n",
            "Training Loss: 0.5476 / Validation Loss: 0.4454\n",
            "Training Accuracy: 77.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 106/1000\n",
            "Training Loss: 0.5404 / Validation Loss: 0.4455\n",
            "Training Accuracy: 78.7%  / Validation Accuracy: 85.8%\n",
            "Epoch 107/1000\n",
            "Training Loss: 0.5426 / Validation Loss: 0.4453\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 85.9%\n",
            "Epoch 108/1000\n",
            "Training Loss: 0.5446 / Validation Loss: 0.4445\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.0%\n",
            "Epoch 109/1000\n",
            "Training Loss: 0.5458 / Validation Loss: 0.4443\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.0%\n",
            "Epoch 110/1000\n",
            "Training Loss: 0.5428 / Validation Loss: 0.4449\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.8%\n",
            "Epoch 111/1000\n",
            "Training Loss: 0.5473 / Validation Loss: 0.4443\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 85.9%\n",
            "Epoch 112/1000\n",
            "Training Loss: 0.5453 / Validation Loss: 0.4448\n",
            "Training Accuracy: 78.3%  / Validation Accuracy: 85.6%\n",
            "Epoch 113/1000\n",
            "Training Loss: 0.5483 / Validation Loss: 0.4445\n",
            "Training Accuracy: 78.0%  / Validation Accuracy: 85.7%\n",
            "Epoch 114/1000\n",
            "Training Loss: 0.5405 / Validation Loss: 0.4442\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 85.7%\n",
            "Epoch 115/1000\n",
            "Training Loss: 0.5432 / Validation Loss: 0.4435\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 85.9%\n",
            "Epoch 116/1000\n",
            "Training Loss: 0.5406 / Validation Loss: 0.4443\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 85.7%\n",
            "Epoch 117/1000\n",
            "Training Loss: 0.5425 / Validation Loss: 0.4428\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.0%\n",
            "Epoch 118/1000\n",
            "Training Loss: 0.5431 / Validation Loss: 0.4430\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 85.9%\n",
            "Epoch 119/1000\n",
            "Training Loss: 0.5423 / Validation Loss: 0.4424\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.3%\n",
            "Epoch 120/1000\n",
            "Training Loss: 0.5432 / Validation Loss: 0.4427\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.0%\n",
            "Epoch 121/1000\n",
            "Training Loss: 0.5457 / Validation Loss: 0.4418\n",
            "Training Accuracy: 78.3%  / Validation Accuracy: 86.1%\n",
            "Epoch 122/1000\n",
            "Training Loss: 0.5435 / Validation Loss: 0.4426\n",
            "Training Accuracy: 78.1%  / Validation Accuracy: 86.0%\n",
            "Epoch 123/1000\n",
            "Training Loss: 0.5418 / Validation Loss: 0.4415\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.0%\n",
            "Epoch 124/1000\n",
            "Training Loss: 0.5455 / Validation Loss: 0.4423\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 86.0%\n",
            "Epoch 125/1000\n",
            "Training Loss: 0.5412 / Validation Loss: 0.4410\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.0%\n",
            "Epoch 126/1000\n",
            "Training Loss: 0.5426 / Validation Loss: 0.4422\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.2%\n",
            "Epoch 127/1000\n",
            "Training Loss: 0.5414 / Validation Loss: 0.4420\n",
            "Training Accuracy: 78.3%  / Validation Accuracy: 86.1%\n",
            "Epoch 128/1000\n",
            "Training Loss: 0.5451 / Validation Loss: 0.4405\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 129/1000\n",
            "Training Loss: 0.5417 / Validation Loss: 0.4417\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 130/1000\n",
            "Training Loss: 0.5424 / Validation Loss: 0.4408\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 131/1000\n",
            "Training Loss: 0.5449 / Validation Loss: 0.4401\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 86.2%\n",
            "Epoch 132/1000\n",
            "Training Loss: 0.5382 / Validation Loss: 0.4412\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 133/1000\n",
            "Training Loss: 0.5410 / Validation Loss: 0.4406\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.3%\n",
            "Epoch 134/1000\n",
            "Training Loss: 0.5419 / Validation Loss: 0.4402\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.2%\n",
            "Epoch 135/1000\n",
            "Training Loss: 0.5420 / Validation Loss: 0.4402\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.3%\n",
            "Epoch 136/1000\n",
            "Training Loss: 0.5427 / Validation Loss: 0.4401\n",
            "Training Accuracy: 78.7%  / Validation Accuracy: 86.3%\n",
            "Epoch 137/1000\n",
            "Training Loss: 0.5421 / Validation Loss: 0.4397\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.1%\n",
            "Epoch 138/1000\n",
            "Training Loss: 0.5410 / Validation Loss: 0.4405\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.3%\n",
            "Epoch 139/1000\n",
            "Training Loss: 0.5404 / Validation Loss: 0.4396\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.2%\n",
            "Epoch 140/1000\n",
            "Training Loss: 0.5437 / Validation Loss: 0.4398\n",
            "Training Accuracy: 78.6%  / Validation Accuracy: 86.2%\n",
            "Epoch 141/1000\n",
            "Training Loss: 0.5428 / Validation Loss: 0.4390\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 86.1%\n",
            "Epoch 142/1000\n",
            "Training Loss: 0.5402 / Validation Loss: 0.4390\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.1%\n",
            "Epoch 143/1000\n",
            "Training Loss: 0.5439 / Validation Loss: 0.4387\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 86.1%\n",
            "Epoch 144/1000\n",
            "Training Loss: 0.5402 / Validation Loss: 0.4398\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.3%\n",
            "Epoch 145/1000\n",
            "Training Loss: 0.5425 / Validation Loss: 0.4381\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.2%\n",
            "Epoch 146/1000\n",
            "Training Loss: 0.5399 / Validation Loss: 0.4380\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.1%\n",
            "Epoch 147/1000\n",
            "Training Loss: 0.5424 / Validation Loss: 0.4378\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.1%\n",
            "Epoch 148/1000\n",
            "Training Loss: 0.5419 / Validation Loss: 0.4384\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 149/1000\n",
            "Training Loss: 0.5423 / Validation Loss: 0.4379\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 86.1%\n",
            "Epoch 150/1000\n",
            "Training Loss: 0.5461 / Validation Loss: 0.4376\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 86.2%\n",
            "Epoch 151/1000\n",
            "Training Loss: 0.5410 / Validation Loss: 0.4385\n",
            "Training Accuracy: 78.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 152/1000\n",
            "Training Loss: 0.5426 / Validation Loss: 0.4383\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.3%\n",
            "Epoch 153/1000\n",
            "Training Loss: 0.5415 / Validation Loss: 0.4382\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.4%\n",
            "Epoch 154/1000\n",
            "Training Loss: 0.5477 / Validation Loss: 0.4370\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 86.1%\n",
            "Epoch 155/1000\n",
            "Training Loss: 0.5404 / Validation Loss: 0.4369\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 86.0%\n",
            "Epoch 156/1000\n",
            "Training Loss: 0.5378 / Validation Loss: 0.4376\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 157/1000\n",
            "Training Loss: 0.5449 / Validation Loss: 0.4370\n",
            "Training Accuracy: 78.7%  / Validation Accuracy: 86.2%\n",
            "Epoch 158/1000\n",
            "Training Loss: 0.5407 / Validation Loss: 0.4371\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.3%\n",
            "Epoch 159/1000\n",
            "Training Loss: 0.5398 / Validation Loss: 0.4370\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.3%\n",
            "Epoch 160/1000\n",
            "Training Loss: 0.5404 / Validation Loss: 0.4365\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 161/1000\n",
            "Training Loss: 0.5395 / Validation Loss: 0.4365\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.4%\n",
            "Epoch 162/1000\n",
            "Training Loss: 0.5411 / Validation Loss: 0.4363\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.3%\n",
            "Epoch 163/1000\n",
            "Training Loss: 0.5429 / Validation Loss: 0.4359\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.2%\n",
            "Epoch 164/1000\n",
            "Training Loss: 0.5411 / Validation Loss: 0.4382\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.4%\n",
            "Epoch 165/1000\n",
            "Training Loss: 0.5450 / Validation Loss: 0.4368\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.2%\n",
            "Epoch 166/1000\n",
            "Training Loss: 0.5412 / Validation Loss: 0.4364\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.3%\n",
            "Epoch 167/1000\n",
            "Training Loss: 0.5411 / Validation Loss: 0.4355\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.4%\n",
            "Epoch 168/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4360\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.4%\n",
            "Epoch 169/1000\n",
            "Training Loss: 0.5437 / Validation Loss: 0.4355\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.3%\n",
            "Epoch 170/1000\n",
            "Training Loss: 0.5408 / Validation Loss: 0.4353\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.3%\n",
            "Epoch 171/1000\n",
            "Training Loss: 0.5368 / Validation Loss: 0.4352\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.1%\n",
            "Epoch 172/1000\n",
            "Training Loss: 0.5429 / Validation Loss: 0.4354\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.2%\n",
            "Epoch 173/1000\n",
            "Training Loss: 0.5393 / Validation Loss: 0.4356\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.3%\n",
            "Epoch 174/1000\n",
            "Training Loss: 0.5401 / Validation Loss: 0.4354\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.2%\n",
            "Epoch 175/1000\n",
            "Training Loss: 0.5408 / Validation Loss: 0.4352\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.3%\n",
            "Epoch 176/1000\n",
            "Training Loss: 0.5438 / Validation Loss: 0.4356\n",
            "Training Accuracy: 78.4%  / Validation Accuracy: 86.4%\n",
            "Epoch 177/1000\n",
            "Training Loss: 0.5371 / Validation Loss: 0.4363\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 178/1000\n",
            "Training Loss: 0.5407 / Validation Loss: 0.4354\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.3%\n",
            "Epoch 179/1000\n",
            "Training Loss: 0.5385 / Validation Loss: 0.4349\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.0%\n",
            "Epoch 180/1000\n",
            "Training Loss: 0.5401 / Validation Loss: 0.4355\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 181/1000\n",
            "Training Loss: 0.5387 / Validation Loss: 0.4354\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.5%\n",
            "Epoch 182/1000\n",
            "Training Loss: 0.5360 / Validation Loss: 0.4343\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.3%\n",
            "Epoch 183/1000\n",
            "Training Loss: 0.5430 / Validation Loss: 0.4352\n",
            "Training Accuracy: 77.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 184/1000\n",
            "Training Loss: 0.5408 / Validation Loss: 0.4340\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 185/1000\n",
            "Training Loss: 0.5415 / Validation Loss: 0.4345\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.1%\n",
            "Epoch 186/1000\n",
            "Training Loss: 0.5381 / Validation Loss: 0.4342\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.3%\n",
            "Epoch 187/1000\n",
            "Training Loss: 0.5380 / Validation Loss: 0.4349\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.4%\n",
            "Epoch 188/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4344\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 189/1000\n",
            "Training Loss: 0.5395 / Validation Loss: 0.4338\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 190/1000\n",
            "Training Loss: 0.5383 / Validation Loss: 0.4342\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 191/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4338\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.3%\n",
            "Epoch 192/1000\n",
            "Training Loss: 0.5429 / Validation Loss: 0.4338\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.4%\n",
            "Epoch 193/1000\n",
            "Training Loss: 0.5413 / Validation Loss: 0.4333\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.4%\n",
            "Epoch 194/1000\n",
            "Training Loss: 0.5392 / Validation Loss: 0.4342\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.4%\n",
            "Epoch 195/1000\n",
            "Training Loss: 0.5405 / Validation Loss: 0.4334\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 196/1000\n",
            "Training Loss: 0.5398 / Validation Loss: 0.4332\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 197/1000\n",
            "Training Loss: 0.5396 / Validation Loss: 0.4330\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.4%\n",
            "Epoch 198/1000\n",
            "Training Loss: 0.5376 / Validation Loss: 0.4328\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 199/1000\n",
            "Training Loss: 0.5422 / Validation Loss: 0.4335\n",
            "Training Accuracy: 78.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 200/1000\n",
            "Training Loss: 0.5366 / Validation Loss: 0.4335\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 201/1000\n",
            "Training Loss: 0.5389 / Validation Loss: 0.4329\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 202/1000\n",
            "Training Loss: 0.5415 / Validation Loss: 0.4341\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.4%\n",
            "Epoch 203/1000\n",
            "Training Loss: 0.5422 / Validation Loss: 0.4332\n",
            "Training Accuracy: 78.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 204/1000\n",
            "Training Loss: 0.5362 / Validation Loss: 0.4327\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 205/1000\n",
            "Training Loss: 0.5359 / Validation Loss: 0.4334\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 206/1000\n",
            "Training Loss: 0.5389 / Validation Loss: 0.4330\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 207/1000\n",
            "Training Loss: 0.5377 / Validation Loss: 0.4335\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 208/1000\n",
            "Training Loss: 0.5365 / Validation Loss: 0.4326\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 209/1000\n",
            "Training Loss: 0.5417 / Validation Loss: 0.4325\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 210/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4324\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 211/1000\n",
            "Training Loss: 0.5401 / Validation Loss: 0.4329\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 212/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4321\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 213/1000\n",
            "Training Loss: 0.5415 / Validation Loss: 0.4319\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 214/1000\n",
            "Training Loss: 0.5399 / Validation Loss: 0.4332\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.2%\n",
            "Epoch 215/1000\n",
            "Training Loss: 0.5367 / Validation Loss: 0.4322\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 216/1000\n",
            "Training Loss: 0.5405 / Validation Loss: 0.4321\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.5%\n",
            "Epoch 217/1000\n",
            "Training Loss: 0.5400 / Validation Loss: 0.4319\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 218/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4323\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 219/1000\n",
            "Training Loss: 0.5385 / Validation Loss: 0.4313\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 220/1000\n",
            "Training Loss: 0.5407 / Validation Loss: 0.4316\n",
            "Training Accuracy: 78.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 221/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4313\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 222/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4319\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 223/1000\n",
            "Training Loss: 0.5402 / Validation Loss: 0.4322\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 224/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4321\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 225/1000\n",
            "Training Loss: 0.5403 / Validation Loss: 0.4314\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 226/1000\n",
            "Training Loss: 0.5371 / Validation Loss: 0.4319\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 227/1000\n",
            "Training Loss: 0.5396 / Validation Loss: 0.4317\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.5%\n",
            "Epoch 228/1000\n",
            "Training Loss: 0.5438 / Validation Loss: 0.4313\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 229/1000\n",
            "Training Loss: 0.5394 / Validation Loss: 0.4308\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.4%\n",
            "Epoch 230/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4311\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 231/1000\n",
            "Training Loss: 0.5413 / Validation Loss: 0.4314\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 232/1000\n",
            "Training Loss: 0.5383 / Validation Loss: 0.4310\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 233/1000\n",
            "Training Loss: 0.5377 / Validation Loss: 0.4307\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 234/1000\n",
            "Training Loss: 0.5399 / Validation Loss: 0.4310\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 235/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4318\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 236/1000\n",
            "Training Loss: 0.5419 / Validation Loss: 0.4306\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 237/1000\n",
            "Training Loss: 0.5368 / Validation Loss: 0.4308\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 238/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4309\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 239/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4309\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 240/1000\n",
            "Training Loss: 0.5375 / Validation Loss: 0.4312\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 241/1000\n",
            "Training Loss: 0.5372 / Validation Loss: 0.4306\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 242/1000\n",
            "Training Loss: 0.5373 / Validation Loss: 0.4310\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 243/1000\n",
            "Training Loss: 0.5364 / Validation Loss: 0.4303\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 244/1000\n",
            "Training Loss: 0.5385 / Validation Loss: 0.4310\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 245/1000\n",
            "Training Loss: 0.5372 / Validation Loss: 0.4308\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 246/1000\n",
            "Training Loss: 0.5392 / Validation Loss: 0.4306\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 247/1000\n",
            "Training Loss: 0.5392 / Validation Loss: 0.4308\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 248/1000\n",
            "Training Loss: 0.5392 / Validation Loss: 0.4301\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 249/1000\n",
            "Training Loss: 0.5381 / Validation Loss: 0.4307\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.4%\n",
            "Epoch 250/1000\n",
            "Training Loss: 0.5381 / Validation Loss: 0.4300\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 251/1000\n",
            "Training Loss: 0.5356 / Validation Loss: 0.4296\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 252/1000\n",
            "Training Loss: 0.5379 / Validation Loss: 0.4299\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 253/1000\n",
            "Training Loss: 0.5362 / Validation Loss: 0.4299\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 254/1000\n",
            "Training Loss: 0.5379 / Validation Loss: 0.4303\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.5%\n",
            "Epoch 255/1000\n",
            "Training Loss: 0.5409 / Validation Loss: 0.4309\n",
            "Training Accuracy: 78.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 256/1000\n",
            "Training Loss: 0.5369 / Validation Loss: 0.4298\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 257/1000\n",
            "Training Loss: 0.5366 / Validation Loss: 0.4298\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 258/1000\n",
            "Training Loss: 0.5354 / Validation Loss: 0.4302\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 259/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4298\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 260/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4297\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 261/1000\n",
            "Training Loss: 0.5367 / Validation Loss: 0.4300\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 262/1000\n",
            "Training Loss: 0.5397 / Validation Loss: 0.4293\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 263/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4295\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 264/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4304\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 265/1000\n",
            "Training Loss: 0.5400 / Validation Loss: 0.4293\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 266/1000\n",
            "Training Loss: 0.5353 / Validation Loss: 0.4292\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.4%\n",
            "Epoch 267/1000\n",
            "Training Loss: 0.5415 / Validation Loss: 0.4292\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.4%\n",
            "Epoch 268/1000\n",
            "Training Loss: 0.5378 / Validation Loss: 0.4294\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.5%\n",
            "Epoch 269/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4289\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 270/1000\n",
            "Training Loss: 0.5356 / Validation Loss: 0.4295\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 271/1000\n",
            "Training Loss: 0.5377 / Validation Loss: 0.4291\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 272/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4295\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 273/1000\n",
            "Training Loss: 0.5376 / Validation Loss: 0.4290\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 274/1000\n",
            "Training Loss: 0.5371 / Validation Loss: 0.4287\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 275/1000\n",
            "Training Loss: 0.5318 / Validation Loss: 0.4297\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 87.0%\n",
            "Epoch 276/1000\n",
            "Training Loss: 0.5382 / Validation Loss: 0.4290\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 277/1000\n",
            "Training Loss: 0.5398 / Validation Loss: 0.4296\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 278/1000\n",
            "Training Loss: 0.5373 / Validation Loss: 0.4288\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 279/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4286\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 280/1000\n",
            "Training Loss: 0.5368 / Validation Loss: 0.4290\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 281/1000\n",
            "Training Loss: 0.5394 / Validation Loss: 0.4289\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 282/1000\n",
            "Training Loss: 0.5380 / Validation Loss: 0.4284\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 283/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4293\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 284/1000\n",
            "Training Loss: 0.5379 / Validation Loss: 0.4287\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 285/1000\n",
            "Training Loss: 0.5362 / Validation Loss: 0.4285\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 286/1000\n",
            "Training Loss: 0.5408 / Validation Loss: 0.4284\n",
            "Training Accuracy: 79.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 287/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4286\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 288/1000\n",
            "Training Loss: 0.5350 / Validation Loss: 0.4285\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.6%\n",
            "Epoch 289/1000\n",
            "Training Loss: 0.5363 / Validation Loss: 0.4285\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 290/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4289\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 291/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4290\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 292/1000\n",
            "Training Loss: 0.5383 / Validation Loss: 0.4286\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 293/1000\n",
            "Training Loss: 0.5406 / Validation Loss: 0.4301\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 294/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4279\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 295/1000\n",
            "Training Loss: 0.5387 / Validation Loss: 0.4280\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 296/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4283\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 297/1000\n",
            "Training Loss: 0.5399 / Validation Loss: 0.4282\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 298/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4280\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 299/1000\n",
            "Training Loss: 0.5379 / Validation Loss: 0.4281\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 300/1000\n",
            "Training Loss: 0.5364 / Validation Loss: 0.4281\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 301/1000\n",
            "Training Loss: 0.5364 / Validation Loss: 0.4284\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 302/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4277\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 303/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4282\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 304/1000\n",
            "Training Loss: 0.5362 / Validation Loss: 0.4277\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 305/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4277\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.4%\n",
            "Epoch 306/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4278\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 307/1000\n",
            "Training Loss: 0.5363 / Validation Loss: 0.4281\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 308/1000\n",
            "Training Loss: 0.5432 / Validation Loss: 0.4283\n",
            "Training Accuracy: 79.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 309/1000\n",
            "Training Loss: 0.5359 / Validation Loss: 0.4274\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 310/1000\n",
            "Training Loss: 0.5372 / Validation Loss: 0.4282\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 311/1000\n",
            "Training Loss: 0.5402 / Validation Loss: 0.4280\n",
            "Training Accuracy: 79.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 312/1000\n",
            "Training Loss: 0.5360 / Validation Loss: 0.4276\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 313/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4274\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 314/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4279\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 315/1000\n",
            "Training Loss: 0.5367 / Validation Loss: 0.4273\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 316/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4277\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 317/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4278\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 318/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4277\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 319/1000\n",
            "Training Loss: 0.5380 / Validation Loss: 0.4273\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 320/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4273\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 321/1000\n",
            "Training Loss: 0.5363 / Validation Loss: 0.4277\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 322/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4271\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 323/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4275\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 324/1000\n",
            "Training Loss: 0.5369 / Validation Loss: 0.4274\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 325/1000\n",
            "Training Loss: 0.5341 / Validation Loss: 0.4272\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 87.0%\n",
            "Epoch 326/1000\n",
            "Training Loss: 0.5381 / Validation Loss: 0.4270\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 327/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4271\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 328/1000\n",
            "Training Loss: 0.5356 / Validation Loss: 0.4274\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 329/1000\n",
            "Training Loss: 0.5373 / Validation Loss: 0.4275\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 330/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4273\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 331/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4270\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 332/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4269\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 333/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4268\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 334/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4272\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 335/1000\n",
            "Training Loss: 0.5363 / Validation Loss: 0.4270\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 336/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4278\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 337/1000\n",
            "Training Loss: 0.5367 / Validation Loss: 0.4268\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 338/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4269\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 339/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4285\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 340/1000\n",
            "Training Loss: 0.5366 / Validation Loss: 0.4280\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 341/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4272\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 342/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4271\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 343/1000\n",
            "Training Loss: 0.5364 / Validation Loss: 0.4278\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.9%\n",
            "Epoch 344/1000\n",
            "Training Loss: 0.5392 / Validation Loss: 0.4271\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 345/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4272\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 346/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4265\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 347/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4266\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.0%\n",
            "Epoch 348/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4265\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 349/1000\n",
            "Training Loss: 0.5353 / Validation Loss: 0.4274\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 350/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4264\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 351/1000\n",
            "Training Loss: 0.5361 / Validation Loss: 0.4267\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 352/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4263\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 87.2%\n",
            "Epoch 353/1000\n",
            "Training Loss: 0.5328 / Validation Loss: 0.4262\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 354/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4267\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 355/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4272\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 356/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4264\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 357/1000\n",
            "Training Loss: 0.5375 / Validation Loss: 0.4261\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 358/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4262\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 359/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4265\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 360/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4263\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 361/1000\n",
            "Training Loss: 0.5379 / Validation Loss: 0.4267\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 362/1000\n",
            "Training Loss: 0.5350 / Validation Loss: 0.4263\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 363/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4264\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 364/1000\n",
            "Training Loss: 0.5388 / Validation Loss: 0.4263\n",
            "Training Accuracy: 79.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 365/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4260\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 366/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4264\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 367/1000\n",
            "Training Loss: 0.5359 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 368/1000\n",
            "Training Loss: 0.5360 / Validation Loss: 0.4262\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 369/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4260\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 370/1000\n",
            "Training Loss: 0.5351 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 87.0%\n",
            "Epoch 371/1000\n",
            "Training Loss: 0.5380 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 372/1000\n",
            "Training Loss: 0.5334 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 87.1%\n",
            "Epoch 373/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 374/1000\n",
            "Training Loss: 0.5350 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 375/1000\n",
            "Training Loss: 0.5334 / Validation Loss: 0.4260\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 376/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 377/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 378/1000\n",
            "Training Loss: 0.5375 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 87.0%\n",
            "Epoch 379/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4258\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 87.1%\n",
            "Epoch 380/1000\n",
            "Training Loss: 0.5354 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 87.1%\n",
            "Epoch 381/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 87.1%\n",
            "Epoch 382/1000\n",
            "Training Loss: 0.5402 / Validation Loss: 0.4269\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 383/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.9%\n",
            "Epoch 384/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4260\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 385/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 386/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 387/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4263\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 388/1000\n",
            "Training Loss: 0.5378 / Validation Loss: 0.4256\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 87.0%\n",
            "Epoch 389/1000\n",
            "Training Loss: 0.5370 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 390/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4254\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 391/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.0%\n",
            "Epoch 392/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4257\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 393/1000\n",
            "Training Loss: 0.5334 / Validation Loss: 0.4255\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 87.1%\n",
            "Epoch 394/1000\n",
            "Training Loss: 0.5354 / Validation Loss: 0.4262\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 395/1000\n",
            "Training Loss: 0.5336 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.9%\n",
            "Epoch 396/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 87.1%\n",
            "Epoch 397/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 398/1000\n",
            "Training Loss: 0.5350 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 399/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4254\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 400/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4256\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 401/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4256\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 402/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.9%\n",
            "Epoch 403/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 404/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 87.1%\n",
            "Epoch 405/1000\n",
            "Training Loss: 0.5375 / Validation Loss: 0.4255\n",
            "Training Accuracy: 79.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 406/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 407/1000\n",
            "Training Loss: 0.5350 / Validation Loss: 0.4259\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.4%\n",
            "Epoch 408/1000\n",
            "Training Loss: 0.5336 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 409/1000\n",
            "Training Loss: 0.5360 / Validation Loss: 0.4260\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 410/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 411/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4257\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 412/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4253\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 413/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4251\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.0%\n",
            "Epoch 414/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4255\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 87.1%\n",
            "Epoch 415/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 416/1000\n",
            "Training Loss: 0.5372 / Validation Loss: 0.4256\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 417/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 418/1000\n",
            "Training Loss: 0.5357 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 419/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4254\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.9%\n",
            "Epoch 420/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4253\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 421/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4251\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 422/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4252\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 423/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4252\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 424/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4252\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 425/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4252\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 426/1000\n",
            "Training Loss: 0.5349 / Validation Loss: 0.4255\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 427/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4259\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 428/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4253\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 429/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4257\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 430/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 431/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4250\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 432/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 433/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 434/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4258\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 435/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4253\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.1%\n",
            "Epoch 436/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4249\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 437/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4249\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 438/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4249\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 439/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4248\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 440/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4250\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 441/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4249\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 442/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4250\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 443/1000\n",
            "Training Loss: 0.5370 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 87.0%\n",
            "Epoch 444/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4256\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 445/1000\n",
            "Training Loss: 0.5336 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 446/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4248\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.0%\n",
            "Epoch 447/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 448/1000\n",
            "Training Loss: 0.5359 / Validation Loss: 0.4246\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 449/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.9%\n",
            "Epoch 450/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4256\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 451/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4246\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 452/1000\n",
            "Training Loss: 0.5354 / Validation Loss: 0.4246\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 453/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4248\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.1%\n",
            "Epoch 454/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 455/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 87.0%\n",
            "Epoch 456/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4258\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.5%\n",
            "Epoch 457/1000\n",
            "Training Loss: 0.5279 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 458/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4248\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 87.0%\n",
            "Epoch 459/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4246\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 460/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4247\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 461/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4251\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 462/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 463/1000\n",
            "Training Loss: 0.5336 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.9%\n",
            "Epoch 464/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4246\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 465/1000\n",
            "Training Loss: 0.5375 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 466/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4251\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 467/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 468/1000\n",
            "Training Loss: 0.5370 / Validation Loss: 0.4246\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 469/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 470/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4246\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 471/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4247\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 87.0%\n",
            "Epoch 472/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4244\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 473/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 87.0%\n",
            "Epoch 474/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 475/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4248\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 476/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 477/1000\n",
            "Training Loss: 0.5352 / Validation Loss: 0.4248\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 87.1%\n",
            "Epoch 478/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4242\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 479/1000\n",
            "Training Loss: 0.5334 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 87.0%\n",
            "Epoch 480/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 481/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4244\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 482/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4244\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 87.0%\n",
            "Epoch 483/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 484/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4242\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 485/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4250\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 486/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4242\n",
            "Training Accuracy: 82.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 487/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4244\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 488/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 489/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 490/1000\n",
            "Training Loss: 0.5328 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 491/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4249\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 492/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4243\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 493/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 494/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4249\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 495/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4243\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 496/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4242\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 497/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4241\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 498/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 499/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4242\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 500/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 501/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4243\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 502/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4239\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 503/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.1%\n",
            "Epoch 504/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4243\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 505/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 87.0%\n",
            "Epoch 506/1000\n",
            "Training Loss: 0.5318 / Validation Loss: 0.4244\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 507/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4248\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 508/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4249\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 509/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 510/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.9%\n",
            "Epoch 511/1000\n",
            "Training Loss: 0.5341 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 512/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4243\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 513/1000\n",
            "Training Loss: 0.5341 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 514/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 515/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 516/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4243\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 517/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4244\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 518/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 519/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 520/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4247\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 521/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4239\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 522/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4241\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 523/1000\n",
            "Training Loss: 0.5349 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 524/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 525/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4240\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 526/1000\n",
            "Training Loss: 0.5358 / Validation Loss: 0.4245\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 527/1000\n",
            "Training Loss: 0.5334 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 528/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 529/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 530/1000\n",
            "Training Loss: 0.5351 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 531/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4240\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 532/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 533/1000\n",
            "Training Loss: 0.5343 / Validation Loss: 0.4240\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 534/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4239\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 535/1000\n",
            "Training Loss: 0.5351 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 536/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.9%\n",
            "Epoch 537/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 538/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 539/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 540/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 541/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4240\n",
            "Training Accuracy: 79.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 542/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 543/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 544/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 545/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 546/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 547/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4236\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 87.0%\n",
            "Epoch 548/1000\n",
            "Training Loss: 0.5338 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 549/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 87.0%\n",
            "Epoch 550/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 551/1000\n",
            "Training Loss: 0.5318 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 87.0%\n",
            "Epoch 552/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4236\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 553/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 554/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 555/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 556/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 557/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 558/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 87.1%\n",
            "Epoch 559/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 87.1%\n",
            "Epoch 560/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 561/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 562/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 563/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 564/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 565/1000\n",
            "Training Loss: 0.5272 / Validation Loss: 0.4244\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 566/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 567/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4242\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 568/1000\n",
            "Training Loss: 0.5377 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 569/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 570/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4236\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 571/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 572/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 87.0%\n",
            "Epoch 573/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 87.0%\n",
            "Epoch 574/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 87.0%\n",
            "Epoch 575/1000\n",
            "Training Loss: 0.5346 / Validation Loss: 0.4239\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 576/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 577/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 578/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 579/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 580/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 581/1000\n",
            "Training Loss: 0.5318 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 582/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 583/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 584/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 585/1000\n",
            "Training Loss: 0.5342 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 586/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 587/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 588/1000\n",
            "Training Loss: 0.5347 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 589/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4244\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 590/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 591/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4236\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 592/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 593/1000\n",
            "Training Loss: 0.5355 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 594/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 595/1000\n",
            "Training Loss: 0.5353 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 596/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 597/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 598/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 599/1000\n",
            "Training Loss: 0.5336 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 600/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 601/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4233\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 602/1000\n",
            "Training Loss: 0.5318 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 603/1000\n",
            "Training Loss: 0.5397 / Validation Loss: 0.4234\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 604/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 605/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.9%\n",
            "Epoch 606/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4236\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.9%\n",
            "Epoch 607/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 608/1000\n",
            "Training Loss: 0.5348 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 609/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 610/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 611/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 612/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 613/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 614/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 615/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4240\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 616/1000\n",
            "Training Loss: 0.5302 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 617/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 618/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 619/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 620/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 621/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 622/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 623/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 624/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 625/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4238\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 626/1000\n",
            "Training Loss: 0.5328 / Validation Loss: 0.4241\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 627/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 628/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 629/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 630/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 631/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 632/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 633/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4236\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 634/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 635/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 636/1000\n",
            "Training Loss: 0.5340 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 637/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 638/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 639/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 640/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4239\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 641/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 642/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 643/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 644/1000\n",
            "Training Loss: 0.5267 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 645/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 646/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4236\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 647/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 648/1000\n",
            "Training Loss: 0.5282 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 649/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 650/1000\n",
            "Training Loss: 0.5328 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 651/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 652/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 653/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 654/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 655/1000\n",
            "Training Loss: 0.5279 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.5%\n",
            "Epoch 656/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 657/1000\n",
            "Training Loss: 0.5330 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 658/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 659/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 660/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4231\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 661/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.6%\n",
            "Epoch 662/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 663/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 664/1000\n",
            "Training Loss: 0.5255 / Validation Loss: 0.4234\n",
            "Training Accuracy: 82.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 665/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 666/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 667/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4243\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 668/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 669/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 670/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 671/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 672/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 673/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 674/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 675/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 676/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 677/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 87.2%\n",
            "Epoch 678/1000\n",
            "Training Loss: 0.5341 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 679/1000\n",
            "Training Loss: 0.5326 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 680/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4228\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 681/1000\n",
            "Training Loss: 0.5298 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 682/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 683/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 684/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 685/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 686/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 687/1000\n",
            "Training Loss: 0.5296 / Validation Loss: 0.4230\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 688/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 689/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4228\n",
            "Training Accuracy: 82.3%  / Validation Accuracy: 86.5%\n",
            "Epoch 690/1000\n",
            "Training Loss: 0.5328 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 691/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 692/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 693/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 694/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 695/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 696/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4237\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 697/1000\n",
            "Training Loss: 0.5353 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 698/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 699/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4234\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 700/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 701/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 702/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 703/1000\n",
            "Training Loss: 0.5269 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 704/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 705/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 706/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 707/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 708/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 709/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 710/1000\n",
            "Training Loss: 0.5269 / Validation Loss: 0.4236\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 711/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 712/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 713/1000\n",
            "Training Loss: 0.5310 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 87.0%\n",
            "Epoch 714/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 715/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4237\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 716/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 717/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 718/1000\n",
            "Training Loss: 0.5302 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 719/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4229\n",
            "Training Accuracy: 82.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 720/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 721/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 722/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 723/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 724/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 725/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 726/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 727/1000\n",
            "Training Loss: 0.5308 / Validation Loss: 0.4232\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 728/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 729/1000\n",
            "Training Loss: 0.5298 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 730/1000\n",
            "Training Loss: 0.5296 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 731/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 732/1000\n",
            "Training Loss: 0.5245 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 733/1000\n",
            "Training Loss: 0.5352 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 734/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.4%\n",
            "Epoch 735/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.9%\n",
            "Epoch 736/1000\n",
            "Training Loss: 0.5241 / Validation Loss: 0.4233\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 87.0%\n",
            "Epoch 737/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 738/1000\n",
            "Training Loss: 0.5269 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 739/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.4%\n",
            "Epoch 740/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 741/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.5%\n",
            "Epoch 742/1000\n",
            "Training Loss: 0.5282 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.6%\n",
            "Epoch 743/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.4%\n",
            "Epoch 744/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.4%\n",
            "Epoch 745/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 746/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 747/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 748/1000\n",
            "Training Loss: 0.5365 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.1%  / Validation Accuracy: 86.5%\n",
            "Epoch 749/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4233\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 750/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 751/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 752/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 753/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 754/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 755/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 756/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 757/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4235\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.9%\n",
            "Epoch 758/1000\n",
            "Training Loss: 0.5257 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 759/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4225\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 760/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 761/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 762/1000\n",
            "Training Loss: 0.5292 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 763/1000\n",
            "Training Loss: 0.5273 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 764/1000\n",
            "Training Loss: 0.5341 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 765/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 766/1000\n",
            "Training Loss: 0.5241 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 767/1000\n",
            "Training Loss: 0.5276 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 768/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 769/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 770/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 771/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 772/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 773/1000\n",
            "Training Loss: 0.5320 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 774/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 775/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 776/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 777/1000\n",
            "Training Loss: 0.5329 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.9%\n",
            "Epoch 778/1000\n",
            "Training Loss: 0.5310 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 779/1000\n",
            "Training Loss: 0.5273 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 780/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 781/1000\n",
            "Training Loss: 0.5345 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 782/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 783/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 784/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 785/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 786/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 787/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 788/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 789/1000\n",
            "Training Loss: 0.5281 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 790/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 791/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 792/1000\n",
            "Training Loss: 0.5331 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.5%\n",
            "Epoch 793/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 794/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 795/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4226\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 796/1000\n",
            "Training Loss: 0.5273 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 797/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 798/1000\n",
            "Training Loss: 0.5270 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 799/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 800/1000\n",
            "Training Loss: 0.5275 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 801/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 802/1000\n",
            "Training Loss: 0.5310 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 803/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 804/1000\n",
            "Training Loss: 0.5339 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 805/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 806/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 807/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 808/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4232\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 809/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 810/1000\n",
            "Training Loss: 0.5344 / Validation Loss: 0.4228\n",
            "Training Accuracy: 79.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 811/1000\n",
            "Training Loss: 0.5269 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 812/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 813/1000\n",
            "Training Loss: 0.5259 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 814/1000\n",
            "Training Loss: 0.5351 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 815/1000\n",
            "Training Loss: 0.5270 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 816/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.5%\n",
            "Epoch 817/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.6%\n",
            "Epoch 818/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 819/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 820/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 821/1000\n",
            "Training Loss: 0.5324 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 822/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 823/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 824/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4228\n",
            "Training Accuracy: 79.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 825/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 826/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.6%\n",
            "Epoch 827/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 828/1000\n",
            "Training Loss: 0.5332 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 829/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 830/1000\n",
            "Training Loss: 0.5298 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 831/1000\n",
            "Training Loss: 0.5292 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 832/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 833/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4231\n",
            "Training Accuracy: 82.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 834/1000\n",
            "Training Loss: 0.5249 / Validation Loss: 0.4238\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 835/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 836/1000\n",
            "Training Loss: 0.5333 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 837/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.9%\n",
            "Epoch 838/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 839/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 840/1000\n",
            "Training Loss: 0.5256 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.9%\n",
            "Epoch 841/1000\n",
            "Training Loss: 0.5263 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 842/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4227\n",
            "Training Accuracy: 79.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 843/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4230\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 844/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.5%\n",
            "Epoch 845/1000\n",
            "Training Loss: 0.5310 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 87.0%\n",
            "Epoch 846/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 847/1000\n",
            "Training Loss: 0.5297 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 848/1000\n",
            "Training Loss: 0.5325 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 849/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 850/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 851/1000\n",
            "Training Loss: 0.5265 / Validation Loss: 0.4225\n",
            "Training Accuracy: 82.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 852/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 853/1000\n",
            "Training Loss: 0.5265 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 854/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 855/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4233\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 856/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 857/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 858/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 859/1000\n",
            "Training Loss: 0.5268 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.6%\n",
            "Epoch 860/1000\n",
            "Training Loss: 0.5262 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 861/1000\n",
            "Training Loss: 0.5270 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 862/1000\n",
            "Training Loss: 0.5264 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 863/1000\n",
            "Training Loss: 0.5282 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 864/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 865/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 866/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 867/1000\n",
            "Training Loss: 0.5277 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.9%\n",
            "Epoch 868/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.5%\n",
            "Epoch 869/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 870/1000\n",
            "Training Loss: 0.5251 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 871/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 872/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 873/1000\n",
            "Training Loss: 0.5337 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 874/1000\n",
            "Training Loss: 0.5276 / Validation Loss: 0.4235\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 875/1000\n",
            "Training Loss: 0.5321 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 876/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 877/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 878/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.6%\n",
            "Epoch 879/1000\n",
            "Training Loss: 0.5276 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 880/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 881/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4231\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 882/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 883/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4227\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 884/1000\n",
            "Training Loss: 0.5248 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 885/1000\n",
            "Training Loss: 0.5316 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 886/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 887/1000\n",
            "Training Loss: 0.5303 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 888/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 889/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 890/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 891/1000\n",
            "Training Loss: 0.5263 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 892/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 893/1000\n",
            "Training Loss: 0.5276 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 894/1000\n",
            "Training Loss: 0.5305 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 895/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 896/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 897/1000\n",
            "Training Loss: 0.5264 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 898/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4236\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 899/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 900/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 901/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 902/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 903/1000\n",
            "Training Loss: 0.5271 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 904/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 905/1000\n",
            "Training Loss: 0.5225 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 906/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4229\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 907/1000\n",
            "Training Loss: 0.5314 / Validation Loss: 0.4222\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 908/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 909/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 910/1000\n",
            "Training Loss: 0.5266 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 911/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4228\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 912/1000\n",
            "Training Loss: 0.5292 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.7%\n",
            "Epoch 913/1000\n",
            "Training Loss: 0.5258 / Validation Loss: 0.4224\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 914/1000\n",
            "Training Loss: 0.5307 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.7%\n",
            "Epoch 915/1000\n",
            "Training Loss: 0.5267 / Validation Loss: 0.4230\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 916/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.6%  / Validation Accuracy: 86.8%\n",
            "Epoch 917/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 918/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 919/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 920/1000\n",
            "Training Loss: 0.5263 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 921/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 922/1000\n",
            "Training Loss: 0.5296 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 923/1000\n",
            "Training Loss: 0.5287 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 924/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 925/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.7%\n",
            "Epoch 926/1000\n",
            "Training Loss: 0.5302 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 927/1000\n",
            "Training Loss: 0.5265 / Validation Loss: 0.4225\n",
            "Training Accuracy: 82.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 928/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 929/1000\n",
            "Training Loss: 0.5284 / Validation Loss: 0.4228\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 930/1000\n",
            "Training Loss: 0.5309 / Validation Loss: 0.4226\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 931/1000\n",
            "Training Loss: 0.5298 / Validation Loss: 0.4232\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 932/1000\n",
            "Training Loss: 0.5291 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 933/1000\n",
            "Training Loss: 0.5258 / Validation Loss: 0.4229\n",
            "Training Accuracy: 82.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 934/1000\n",
            "Training Loss: 0.5292 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 935/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4244\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 936/1000\n",
            "Training Loss: 0.5292 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 937/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4225\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 938/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 939/1000\n",
            "Training Loss: 0.5282 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 940/1000\n",
            "Training Loss: 0.5335 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.8%\n",
            "Epoch 941/1000\n",
            "Training Loss: 0.5278 / Validation Loss: 0.4226\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.9%\n",
            "Epoch 942/1000\n",
            "Training Loss: 0.5294 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 943/1000\n",
            "Training Loss: 0.5317 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 944/1000\n",
            "Training Loss: 0.5269 / Validation Loss: 0.4227\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.5%\n",
            "Epoch 945/1000\n",
            "Training Loss: 0.5272 / Validation Loss: 0.4229\n",
            "Training Accuracy: 81.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 946/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 947/1000\n",
            "Training Loss: 0.5248 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.6%\n",
            "Epoch 948/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 949/1000\n",
            "Training Loss: 0.5255 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 950/1000\n",
            "Training Loss: 0.5279 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 951/1000\n",
            "Training Loss: 0.5289 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.7%\n",
            "Epoch 952/1000\n",
            "Training Loss: 0.5302 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 953/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4222\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 954/1000\n",
            "Training Loss: 0.5265 / Validation Loss: 0.4222\n",
            "Training Accuracy: 82.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 955/1000\n",
            "Training Loss: 0.5327 / Validation Loss: 0.4228\n",
            "Training Accuracy: 79.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 956/1000\n",
            "Training Loss: 0.5276 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.5%  / Validation Accuracy: 86.8%\n",
            "Epoch 957/1000\n",
            "Training Loss: 0.5323 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 958/1000\n",
            "Training Loss: 0.5271 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.6%\n",
            "Epoch 959/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 960/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.8%\n",
            "Epoch 961/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 962/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4229\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 963/1000\n",
            "Training Loss: 0.5300 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.6%\n",
            "Epoch 964/1000\n",
            "Training Loss: 0.5281 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.7%\n",
            "Epoch 965/1000\n",
            "Training Loss: 0.5306 / Validation Loss: 0.4225\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 966/1000\n",
            "Training Loss: 0.5286 / Validation Loss: 0.4222\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.7%\n",
            "Epoch 967/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 968/1000\n",
            "Training Loss: 0.5271 / Validation Loss: 0.4221\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 969/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4229\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 970/1000\n",
            "Training Loss: 0.5280 / Validation Loss: 0.4221\n",
            "Training Accuracy: 81.8%  / Validation Accuracy: 86.8%\n",
            "Epoch 971/1000\n",
            "Training Loss: 0.5301 / Validation Loss: 0.4222\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 972/1000\n",
            "Training Loss: 0.5263 / Validation Loss: 0.4222\n",
            "Training Accuracy: 82.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 973/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 974/1000\n",
            "Training Loss: 0.5245 / Validation Loss: 0.4225\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 975/1000\n",
            "Training Loss: 0.5319 / Validation Loss: 0.4222\n",
            "Training Accuracy: 80.5%  / Validation Accuracy: 86.4%\n",
            "Epoch 976/1000\n",
            "Training Loss: 0.5283 / Validation Loss: 0.4220\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.8%\n",
            "Epoch 977/1000\n",
            "Training Loss: 0.5290 / Validation Loss: 0.4223\n",
            "Training Accuracy: 82.0%  / Validation Accuracy: 86.7%\n",
            "Epoch 978/1000\n",
            "Training Loss: 0.5281 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 979/1000\n",
            "Training Loss: 0.5312 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.7%  / Validation Accuracy: 86.6%\n",
            "Epoch 980/1000\n",
            "Training Loss: 0.5302 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 981/1000\n",
            "Training Loss: 0.5313 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.7%\n",
            "Epoch 982/1000\n",
            "Training Loss: 0.5311 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.2%  / Validation Accuracy: 86.6%\n",
            "Epoch 983/1000\n",
            "Training Loss: 0.5299 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 984/1000\n",
            "Training Loss: 0.5304 / Validation Loss: 0.4222\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 985/1000\n",
            "Training Loss: 0.5267 / Validation Loss: 0.4223\n",
            "Training Accuracy: 82.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 986/1000\n",
            "Training Loss: 0.5275 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.6%  / Validation Accuracy: 86.7%\n",
            "Epoch 987/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4234\n",
            "Training Accuracy: 81.0%  / Validation Accuracy: 86.8%\n",
            "Epoch 988/1000\n",
            "Training Loss: 0.5315 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.6%\n",
            "Epoch 989/1000\n",
            "Training Loss: 0.5257 / Validation Loss: 0.4228\n",
            "Training Accuracy: 81.3%  / Validation Accuracy: 86.8%\n",
            "Epoch 990/1000\n",
            "Training Loss: 0.5310 / Validation Loss: 0.4224\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.5%\n",
            "Epoch 991/1000\n",
            "Training Loss: 0.5275 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.5%\n",
            "Epoch 992/1000\n",
            "Training Loss: 0.5293 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.3%  / Validation Accuracy: 86.7%\n",
            "Epoch 993/1000\n",
            "Training Loss: 0.5270 / Validation Loss: 0.4231\n",
            "Training Accuracy: 81.4%  / Validation Accuracy: 86.8%\n",
            "Epoch 994/1000\n",
            "Training Loss: 0.5322 / Validation Loss: 0.4225\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.6%\n",
            "Epoch 995/1000\n",
            "Training Loss: 0.5285 / Validation Loss: 0.4223\n",
            "Training Accuracy: 80.7%  / Validation Accuracy: 86.4%\n",
            "Epoch 996/1000\n",
            "Training Loss: 0.5250 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.2%  / Validation Accuracy: 86.5%\n",
            "Epoch 997/1000\n",
            "Training Loss: 0.5248 / Validation Loss: 0.4223\n",
            "Training Accuracy: 81.1%  / Validation Accuracy: 86.5%\n",
            "Epoch 998/1000\n",
            "Training Loss: 0.5260 / Validation Loss: 0.4223\n",
            "Training Accuracy: 82.6%  / Validation Accuracy: 86.4%\n",
            "Epoch 999/1000\n",
            "Training Loss: 0.5288 / Validation Loss: 0.4227\n",
            "Training Accuracy: 80.9%  / Validation Accuracy: 86.8%\n",
            "Epoch 1000/1000\n",
            "Training Loss: 0.5295 / Validation Loss: 0.4224\n",
            "Training Accuracy: 80.8%  / Validation Accuracy: 86.5%\n",
            "Predictions on the test set: [0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame(dict(yhat=test_pred, y=test_dataset.labels))\n",
        "test['correct'] = test.yhat==test.y\n",
        "test.correct.sum() / test.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNfdjN7Wr3VT",
        "outputId": "7cbc4018-1808-4569-f2c9-fcb79a8e64c4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8740978348035284"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n",
        "ax[0].plot(train_loss[20:], label='Training loss', alpha=0.5)\n",
        "ax[0].plot(val_loss[20:], label='Validation loss', alpha=0.5)\n",
        "ax[0].set_title('Training/Validation Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(train_acc[20:], label='Training acc')\n",
        "ax[1].plot(val_acc[20:], label='Validation acc', alpha=0.5)\n",
        "ax[1].set_title('Training/Validation Accuracy')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "gBZ02ejMIDWx",
        "outputId": "d5265a48-f163-424e-b89b-94a1a47b8c06"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x6bUioSKNi4",
        "outputId": "993f079d-3f43-4231-c856-eef3d4f74c8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}